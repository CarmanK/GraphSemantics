{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from rank_bm25 import BM25Okapi\n",
    "import json\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the json file from kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-cd6fa70f2083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df_layer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output_data/layer_1_output_10.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    535\u001b[0m             )\n\u001b[1;32m    536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 871\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "data_df_layer_1 = pd.read_json('./top_k_output/layer_1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the pair of unique phrase in layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phrase_list = np.unique(data_df_layer_1['phrase'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phrase_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the unique phrase in layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = list(pd.read_json('./top_k_output/layer_1.json',typ='series').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of list(unique phrase) for current pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop throught every pair of phrase\n",
    "list_of_phrase_list = []\n",
    "for i in range(len(unique_phrase_list)):\n",
    "    tmplist =[]\n",
    "    for j in range(len(p_list)):\n",
    "        if p_list[j] in unique_phrase_list[i]:\n",
    "            tmplist.append(p_list[j])\n",
    "    list_of_phrase_list.append(tmplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention: Every sentence in the articles from the pool is a candidate sentence for the final summary.\n",
    "# step: compute a BM25 score for every candidate sentence\n",
    "\n",
    "# to compute BM25\n",
    "# 1. find all sentence in current layer(done)\n",
    "# 2. index all sentence(done)\n",
    "# 3. compute score for all current sentence\n",
    "# 4. question here-> should we use the sentence with highest score \n",
    "# to cover the phrase? or to cover pair of phrase?\n",
    "# If so, after phrase been recoverd, tag the sentence been used,\n",
    "# recompute the BM25 in unused sentence pool\n",
    "# and iterate all sentece until all phrase been coverd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the article pool now\n",
    "article_list = data_df_layer_1['article'].values\n",
    "#for each article, find all sentence\n",
    "article_list[0]\n",
    "sentence_dic = {}\n",
    "list_sentence = []\n",
    "s_count = 0 #sentence index\n",
    "for i in range(len(article_list)):\n",
    "    #for every sentence, if not in sentence_list, push sentence in list\n",
    "    tmp_sentence_list = article_list[i].split(\".\")\n",
    "    for j in range(len(tmp_sentence_list)):\n",
    "        if tmp_sentence_list[j] not in article_list:\n",
    "            sentence_dic[s_count] = tmp_sentence_list[j]\n",
    "            list_sentence.append(tmp_sentence_list[j])\n",
    "            s_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentence = np.unique(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25_score(sentence_list,unique_phrase_list,p_list):\n",
    "    #at each iteration\n",
    "    #find the sentence that could lead to the highest bm25\n",
    "        #1.for every pair of phrase, find the max score of that sentence, save that score and the respective sentence,\n",
    "        #2.pick the highest score, also recover that sentence\n",
    "        #3.find how many phrase this sentece been touched, tag those phrase, pop those phrase out of phrase list\n",
    "        #4.if pair of phrase that lead to highest score contains all some at least two of phrase that been poped out,\n",
    "        #5.pop out that phrase pair in pair list\n",
    "        #6.finsihed current iteration\n",
    "        #7.check whether the lenght of phrass list becomes 0 or num of iteration hit max\n",
    "        #8.if either happens, exit the problem, return the sentence list, and the touched phrase list\n",
    "        \n",
    "    \n",
    "    answer_sentence_list = []\n",
    "    touched_phrase_list = []\n",
    "    count = 0\n",
    "    while len(p_list) > 0 and len(touched_phrase_list) < len(p_list):\n",
    "        #step1\n",
    "        #create a data structure to save score for current query(as pair of phrase)\n",
    "        #in the future, implement the max-heap ds here O(nlogn) push, O(1) peek\n",
    "        score_list_current_iter = []\n",
    "        sentence_idx_list = []\n",
    "        cur_pair_phrase_dic = {}\n",
    "        for i in range(len(unique_phrase_list)):\n",
    "            #compute bm25 score use current phrase pair as query\n",
    "            bm25 = BM25Okapi(sentence_list) #create class of bm25\n",
    "            doc_scores = bm25.get_scores(unique_phrase_list[i])\n",
    "            sentence_loc = np.argmax(doc_scores)  #the index num of max-score sentence in the sen_list\n",
    "            sentence_score = np.max(doc_scores)   #the max score over all score of sentence for current query\n",
    "            score_list_current_iter.append(sentence_score)\n",
    "            sentence_idx_list.append(sentence_loc)\n",
    "            if sentence_score not in cur_pair_phrase_dic:\n",
    "                cur_pair_phrase_dic[sentence_score] = i\n",
    "        #step2\n",
    "        highest_score_index = np.argmax(score_list_current_iter)\n",
    "        high_sen = sentence_list[sentence_idx_list[highest_score_index]] \n",
    "        answer_sentence_list.append(high_sen)\n",
    "        #step three\n",
    "        cur_touched_phrase = []  #record how many phrase been touched by this sentence\n",
    "#         print('current lengh of p_list is', len(p_list))\n",
    "        list_deleted = []\n",
    "        for pos in range(len(p_list)):\n",
    "#             print('current pos is', pos)\n",
    "#             print('what is that ', p_list[pos])\n",
    "            if p_list[pos] in high_sen:\n",
    "                if p_list[pos] not in cur_touched_phrase:\n",
    "                    cur_touched_phrase.append(p_list[pos])\n",
    "#                 p_list.remove(p_list[pos])\n",
    "                #remove phrase list\n",
    "        #<wait>\n",
    "#         for i in range(len(cur_touched_phrase)):\n",
    "#             if cur_touched_phrase[i] in p_list:\n",
    "#                 p_list.remove(cur_touched_phrase[i])\n",
    "        #<wait>\n",
    "#         print('current sentence is', sentence_list[highest_score_index])\n",
    "#         print('len of unique pair  list', len(unique_phrase_list))\n",
    "        print('lengh of touched phrase', len(cur_touched_phrase))\n",
    "#         print('current count is', count)\n",
    "#         print('lengh of sentence list', len(sentence_list))\n",
    "\n",
    "#         #if the current pair of phrase that lead to this sentence which has max score contains two phrase in cur_touched_phrase\n",
    "#         #pop this pair of phrase out of pair of phrase list\n",
    "#         #return the pair of phrase by useing dic\n",
    "        curpair = unique_phrase_list[cur_pair_phrase_dic[np.max(score_list_current_iter)]] \n",
    "#         #count how many phrase in cur_touched_phrase \n",
    "        count_now = 0\n",
    "        for loc in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[loc] in curpair:\n",
    "                count_now+=1\n",
    "        if count_now>=2 and curpair in unique_phrase_list:\n",
    "#             print('hahahahahahhaa six six six')\n",
    "            unique_phrase_list.remove(curpair)\n",
    "        count +=1\n",
    "        #remove phrase list\n",
    "        #unique_phrase_list.remove(curpair)\n",
    "        #remove sentence\n",
    "        sentence_list.remove(high_sen)\n",
    "        \n",
    "        #add cur touched list to total touched list\n",
    "        for inx in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[inx] not in touched_phrase_list:\n",
    "                touched_phrase_list.append(cur_touched_phrase[inx])\n",
    "        print('now total touched length', len(touched_phrase_list))\n",
    "        #create a pair phrase function based on the cur_touched_phrase_process\n",
    "        tmp_phrase_pair = []\n",
    "        for p in range(len(cur_touched_phrase)):\n",
    "            for q in range(p,len(cur_touched_phrase)):\n",
    "                if cur_touched_phrase[p] != cur_touched_phrase[q]:\n",
    "                    tmp_phrase_pair.append([cur_touched_phrase[p],cur_touched_phrase[q]])\n",
    "        #iter thorught unique_phrase_list if pair is exist in touched list, dequeue them\n",
    "        \n",
    "        deletelist = []\n",
    "#         print('tmo coutched list is', len(tmp_phrase_pair))\n",
    "#         print('tmp phrase pari look like ', tmp_phrase_pair)\n",
    "        for p2 in range(len(tmp_phrase_pair)):\n",
    "            for q2 in range(len(unique_phrase_list)):\n",
    "                if tmp_phrase_pair[p2][0] in unique_phrase_list[q2] and tmp_phrase_pair[p2][1] in unique_phrase_list[q2]:\n",
    "                    if unique_phrase_list[q2] not in deletelist:\n",
    "                        deletelist.append(unique_phrase_list[q2])\n",
    "        \n",
    "#         print('look of deletelist, ', deletelist)\n",
    "#         print('len of delete list', len(deletelist))\n",
    "        for p3 in range(len(deletelist)):\n",
    "            if deletelist[p3] in unique_phrase_list:\n",
    "                unique_phrase_list.remove(deletelist[p3])\n",
    "#         print('len of unique list is', len(unique_phrase_list))\n",
    "        print('num of iteration now is', count)\n",
    "\n",
    "    return answer_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cover(sentence_list,unique_phrase_list,p_list):\n",
    "    #at each iteration\n",
    "        #find the sentence that cover most number of unvisted phrase\n",
    "        #mark those phrase as visited (pop)\n",
    "        #mark the sentence as visited (pop)\n",
    "    answer_sentence_list = []\n",
    "    touch_count_dic = []\n",
    "    count = 0\n",
    "    while len(p_list) > 0:\n",
    "        #create a data structure to save how many unvisited phrase the current sentence touched\n",
    "        touch_count_dic = {} #key as num of phrase touched, value is a list of index of sentence\n",
    "        global_max_count = 0\n",
    "        for i in range(len(sentence_list)):\n",
    "            #compute num of touched\n",
    "            tmpcount = 0\n",
    "            for j in range(len(p_list)):\n",
    "                if p_list[j] in sentence_list[i]:\n",
    "                    tmpcount+=1\n",
    "            if tmpcount > global_max_count:\n",
    "                global_max_count = tmpcount\n",
    "            # save current result in dic\n",
    "            if tmpcount in touch_count_dic:\n",
    "                #return the list\n",
    "                curlist = touch_count_dic.get(tmpcount)\n",
    "                curlist.append(i)\n",
    "            else:\n",
    "                tmplist = []\n",
    "                tmplist.append(i)\n",
    "                touch_count_dic[tmpcount] = tmplist\n",
    "        #use the global max count to return lit of index of sentence that lead to the max current count\n",
    "        \n",
    "        list_of_max_index_sentence = touch_count_dic[global_max_count]\n",
    "        #pick the first one\n",
    "        selected_max_sentence_index = list_of_max_index_sentence[0]\n",
    "        selected_max_sentence = sentence_list[selected_max_sentence_index]\n",
    "        #set cover\n",
    "        visited_list = []\n",
    "#         print('what is sentence now', selected_max_sentence)\n",
    "        \n",
    "        for loc in range(len(p_list)):\n",
    "            if p_list[loc] in selected_max_sentence and p_list[loc] not in visited_list:\n",
    "                visited_list.append(p_list[loc])\n",
    "        #delete all visited list\n",
    "        print('visted length is', len(visited_list))\n",
    "        for pos2 in range(len(visited_list)):\n",
    "            p_list.remove(visited_list[pos2])\n",
    "        answer_sentence_list.append(selected_max_sentence)\n",
    "        #remove the current sentencn\n",
    "        sentence_list.pop(selected_max_sentence_index)\n",
    "        print('length of sentence list is', len(sentence_list))\n",
    "    return answer_sentence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotating_function(answer,p_list): #only mark the first occurance of a phrase exist in sentence\n",
    "    #iter through every answer\n",
    "    for i in range(len(answer)):\n",
    "        for j in range(len(p_list)):\n",
    "            if p_list[j] in answer[i]:\n",
    "                #find the starting index\n",
    "                start = answer[i].find(p_list[j])\n",
    "                end = start + len(p_list[j])\n",
    "                answer[i] = answer[i][0:start] + colored(p_list[j],'red') + answer[i][end:]\n",
    "    for i in range(len(answer)):\n",
    "        print('index :', i, '', answer[i] +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_cover' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9b0849d5c94f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_phrase_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'set_cover' is not defined"
     ]
    }
   ],
   "source": [
    "answer = set_cover(list(list_sentence),list(unique_phrase_list),p_list.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = [' In particular, we identified an apparent elongation in the bond distance between Sr and one of the two terminal water ligands of Ca(2+), W3, whereas that of the Sr-W4 distance was not much changed',\n",
    " ' While the combination of metals is reminiscent of respiratory haem-copper oxidases, the oxidation-labile Cu(I) centre of MccA did not seem to undergo a redox transition during catalysis',\n",
    " ' Furthermore, temperature-dependent line-width broadening in partially reduced samples established that the aromatic ring at position 43 participates in the control of the kinetics of intramolecular electron transfer',\n",
    " ' Intact MccA tightly bound SO2 at haem 2, a dehydration product of the substrate sulfite that was partially turned over due to photoreduction by X-ray irradiation, yielding the reaction intermediate SO',\n",
    " ' The nine-haem cytochrome c (9Hcc), previously described as having 12 haem groups, was isolated from cells of Desulfovibrio desulfuricans ATCC 27774, grown under both nitrate- and sulphate-respiring conditions',\n",
    " '1 A resolution and its implications in the mechanism of water oxidatio Oxygen-evolving complex of photosystem II (PSII) is a tetra-manganese calcium penta-oxygenic cluster (Mn4CaO5) catalyzing light-induced water oxidation through several intermediate states (S-states) by a mechanism that is not fully understood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 0   In particular, we identified an apparent elongation in the bond distance between \u001b[31mSr\u001b[0m and one of the two terminal water ligands of \u001b[31mCa\u001b[0m(2+), \u001b[31mW3\u001b[0m, whereas that of the Sr-W4 distance was not much changed\n",
      "\n",
      "index : 1   While the combination of metals is reminiscent of respiratory haem-\u001b[31mcopper\u001b[0m oxidases, the oxidation-labile \u001b[31mCu\u001b[0m(I) centre of MccA did not seem to undergo a \u001b[31mredox\u001b[0m transition during catalysis\n",
      "\n",
      "index : 2   Furthermore, temperature-dependent line-width broadening in partially reduced samples established that the \u001b[31maromatic ring\u001b[0m at position 43 participates in the control of the kinetics of intramolecular electron transfer\n",
      "\n",
      "index : 3   Intact MccA tightly bound SO2 at haem 2, a dehydration product of the substrate \u001b[31msulfite\u001b[0m that was partially turned over due to photoreduction by X-ray irradiation, yielding the reaction intermediate SO\n",
      "\n",
      "index : 4   The nine-haem cytochrome c (9Hcc), previously described as having 12 haem groups, was isolated from cells of Desulfovibrio desulfuricans \u001b[31mATCC\u001b[0m 27774, grown under both nitrate- and sulphate-respiring conditions\n",
      "\n",
      "index : 5  1 A resolution and its implications in the mechanism of water oxidatio Oxygen-evolving complex of \u001b[31mphotosystem II\u001b[0m (PSII) is a tetra-manganese calcium penta-oxygenic cluster (Mn4\u001b[31mCa\u001b[0mO5) catalyzing light-induced water oxidation through several intermediate states (S-states) by a mechanism that is not fully understood\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotating_function(answer.copy(),p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = ['Sr','sulfite','Ca','Cu','aromatic ring','copper','redox','ATCC','W3','photosystem II']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengh of touched phrase 2\n",
      "now total touched length 2\n",
      "num of iteration now is 1\n",
      "lengh of touched phrase 1\n",
      "now total touched length 3\n",
      "num of iteration now is 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "num of iteration now is 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "num of iteration now is 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "num of iteration now is 5\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "num of iteration now is 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "num of iteration now is 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "num of iteration now is 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 4\n",
      "num of iteration now is 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 10\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 11\n",
      "lengh of touched phrase 1\n",
      "now total touched length 4\n",
      "num of iteration now is 12\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 13\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 14\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 15\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 16\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 17\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "num of iteration now is 18\n",
      "lengh of touched phrase 3\n",
      "now total touched length 5\n",
      "num of iteration now is 19\n",
      "lengh of touched phrase 2\n",
      "now total touched length 6\n",
      "num of iteration now is 20\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 21\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 22\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "num of iteration now is 23\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 24\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 25\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 26\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "num of iteration now is 27\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "num of iteration now is 28\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 29\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 30\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 31\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 32\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 33\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 34\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 35\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "num of iteration now is 36\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 37\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 38\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 39\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 40\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "num of iteration now is 41\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "num of iteration now is 42\n",
      "lengh of touched phrase 2\n",
      "now total touched length 7\n",
      "num of iteration now is 43\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "num of iteration now is 44\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "num of iteration now is 45\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "num of iteration now is 46\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "num of iteration now is 47\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "num of iteration now is 48\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "num of iteration now is 49\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 50\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 51\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 52\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 53\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 54\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 55\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 56\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 57\n",
      "lengh of touched phrase 2\n",
      "now total touched length 8\n",
      "num of iteration now is 58\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 59\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 60\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 61\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 62\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 63\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 64\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 65\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 66\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 67\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 68\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 69\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 70\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 71\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "num of iteration now is 72\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 73\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "num of iteration now is 74\n",
      "lengh of touched phrase 3\n",
      "now total touched length 9\n",
      "num of iteration now is 75\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 76\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 77\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 78\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 79\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 80\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 81\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 82\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 83\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 84\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 85\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 86\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 87\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 88\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 89\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 90\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 91\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 92\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 93\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 94\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 95\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 96\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 97\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 98\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 99\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 100\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 101\n",
      "lengh of touched phrase 2\n",
      "now total touched length 9\n",
      "num of iteration now is 102\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 103\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 104\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 106\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 107\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 108\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 109\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 110\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 111\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 112\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 113\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 114\n",
      "lengh of touched phrase 2\n",
      "now total touched length 9\n",
      "num of iteration now is 115\n",
      "lengh of touched phrase 2\n",
      "now total touched length 9\n",
      "num of iteration now is 116\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 117\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 118\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 119\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 120\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 121\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 122\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 123\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 124\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 125\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 126\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 127\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "num of iteration now is 128\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 129\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "num of iteration now is 130\n",
      "lengh of touched phrase 1\n",
      "now total touched length 10\n",
      "num of iteration now is 131\n"
     ]
    }
   ],
   "source": [
    "answer = BM25_score(list(list_sentence),list(unique_phrase_list),p_list.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./2d_output/layer_1_output.json', 'w') as outfile:\n",
    "    json.dump(answer, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In particular, we identified an apparent elongation in the bond distance between \u001b[31mSr\u001b[0m and one of the two terminal water ligands of Ca(2+), W3, whereas that of the Sr-W4 distance was not much changed\n"
     ]
    }
   ],
   "source": [
    "print(answer[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the json file from kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_layer_1 = pd.read_json('../layer_1_output_2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the pair of unique phrase in layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phrase_list = np.unique(data_df_layer_1['phrase'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the unique phrase in layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = list(pd.read_json('./top_k_output/layer_1.json',typ='series').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of list(unique phrase) for current pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop throught every pair of phrase\n",
    "list_of_phrase_list = []\n",
    "for i in range(len(unique_phrase_list)):\n",
    "    tmplist =[]\n",
    "    for j in range(len(p_list)):\n",
    "        if p_list[j] in unique_phrase_list[i]:\n",
    "            tmplist.append(p_list[j])\n",
    "    list_of_phrase_list.append(tmplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATCC Ca', 'ATCC Haem', 'ATCC Hmc', 'ATCC aromatic ring',\n",
       "       'ATCC enzymatic', 'ATCC member', 'ATCC nitrate', 'ATCC sulfite',\n",
       "       'Ca Haem', 'Ca Hmc', 'Ca enzymatic', 'Ca member', 'Ca nitrate',\n",
       "       'Haem Hmc', 'Haem enzymatic', 'Haem member', 'Haem nitrate',\n",
       "       'Hmc enzymatic', 'Hmc member', 'Hmc nitrate', 'Sr ATCC', 'Sr Ca',\n",
       "       'Sr Haem', 'Sr Hmc', 'Sr aromatic ring', 'Sr enzymatic',\n",
       "       'Sr member', 'Sr nitrate', 'Sr sulfite', 'aromatic ring Ca',\n",
       "       'aromatic ring Haem', 'aromatic ring Hmc',\n",
       "       'aromatic ring enzymatic', 'aromatic ring member',\n",
       "       'aromatic ring nitrate', 'enzymatic member', 'enzymatic nitrate',\n",
       "       'member nitrate', 'sulfite Ca', 'sulfite Haem', 'sulfite Hmc',\n",
       "       'sulfite aromatic ring', 'sulfite enzymatic', 'sulfite member',\n",
       "       'sulfite nitrate'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention: Every sentence in the articles from the pool is a candidate sentence for the final summary.\n",
    "# step: compute a BM25 score for every candidate sentence\n",
    "\n",
    "# to compute BM25\n",
    "# 1. find all sentence in current layer(done)\n",
    "# 2. index all sentence(done)\n",
    "# 3. compute score for all current sentence\n",
    "# 4. question here-> should we use the sentence with highest score \n",
    "# to cover the phrase?\n",
    "# If so, after phrase been recoverd, tag the sentence been used,\n",
    "# recompute the BM25 in unused sentence pool\n",
    "# and iterate all sentece until all phrase been coverd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the article pool now\n",
    "article_list = data_df_layer_1['article'].values\n",
    "#for each article, find all sentence\n",
    "article_list[0]\n",
    "sentence_dic = {}\n",
    "list_sentence = []\n",
    "s_count = 0 #sentence index\n",
    "for i in range(len(article_list)):\n",
    "    #for every sentence, if not in sentence_list, push sentence in list\n",
    "    tmp_sentence_list = article_list[i].split(\".\")\n",
    "    for j in range(len(tmp_sentence_list)):\n",
    "        if tmp_sentence_list[j] not in article_list:\n",
    "            sentence_dic[s_count] = tmp_sentence_list[j]\n",
    "            list_sentence.append(tmp_sentence_list[j])\n",
    "            s_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentence = np.unique(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25_score(sentence_list,unique_phrase_list,p_list,iter_num):\n",
    "    #at each iteration\n",
    "    #find the sentence that could lead to the highest bm25\n",
    "        #1.for every pair of phrase, find the max score of that sentence, save that score and the respective sentence,\n",
    "        #2.pick the highest score, also recover that sentence\n",
    "        #3.find how many phrase this sentece been touched, tag those phrase, pop those phrase out of phrase list\n",
    "        #4.if pair of phrase that lead to highest score contains all some at least two of phrase that been poped out,\n",
    "        #5.pop out that phrase pair in pair list\n",
    "        #6.finsihed current iteration\n",
    "        #7.check whether the lenght of phrass list becomes 0 or num of iteration hit max\n",
    "        #8.if either happens, exit the problem, return the sentence list, and the touched phrase list\n",
    "        \n",
    "    \n",
    "    answer_sentence_list = []\n",
    "    touched_phrase_list = []\n",
    "    count = 0\n",
    "    while len(p_list) > 0 and count < iter_num and len(touched_phrase_list) < len(p_list):\n",
    "        #step1\n",
    "        #create a data structure to save score for current query(as pair of phrase)\n",
    "        #in the future, implement the max-heap ds here O(nlogn) push, O(1) peek\n",
    "        score_list_current_iter = []\n",
    "        sentence_idx_list = []\n",
    "        cur_pair_phrase_dic = {}\n",
    "        for i in range(len(unique_phrase_list)):\n",
    "            #compute bm25 score use current phrase pair as query\n",
    "            bm25 = BM25Okapi(sentence_list) #create class of bm25\n",
    "            doc_scores = bm25.get_scores(unique_phrase_list[i])\n",
    "            sentence_loc = np.argmax(doc_scores)  #the index num of max-score sentence in the sen_list\n",
    "            sentence_score = np.max(doc_scores)   #the max score over all score of sentence for current query\n",
    "            score_list_current_iter.append(sentence_score)\n",
    "            sentence_idx_list.append(sentence_loc)\n",
    "            if sentence_score not in cur_pair_phrase_dic:\n",
    "                cur_pair_phrase_dic[sentence_score] = i\n",
    "        #step2\n",
    "        highest_score_index = np.argmax(score_list_current_iter)\n",
    "        high_sen = sentence_list[sentence_idx_list[highest_score_index]] \n",
    "        answer_sentence_list.append(high_sen)\n",
    "        #step three\n",
    "        cur_touched_phrase = []  #record how many phrase been touched by this sentence\n",
    "#         print('current lengh of p_list is', len(p_list))\n",
    "        list_deleted = []\n",
    "        for pos in range(len(p_list)):\n",
    "#             print('current pos is', pos)\n",
    "#             print('what is that ', p_list[pos])\n",
    "            if p_list[pos] in high_sen:\n",
    "                if p_list[pos] not in cur_touched_phrase:\n",
    "                    cur_touched_phrase.append(p_list[pos])\n",
    "#                 p_list.remove(p_list[pos])\n",
    "                #remove phrase list\n",
    "        for i in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[i] in p_list:\n",
    "                p_list.remove(cur_touched_phrase[i])\n",
    "#         print('current sentence is', sentence_list[highest_score_index])\n",
    "#         print('len of unique pair  list', len(unique_phrase_list))\n",
    "        print('lengh of touched phrase', len(cur_touched_phrase))\n",
    "#         print('current count is', count)\n",
    "#         print('lengh of sentence list', len(sentence_list))\n",
    "\n",
    "#         #if the current pair of phrase that lead to this sentence which has max score contains two phrase in cur_touched_phrase\n",
    "#         #pop this pair of phrase out of pair of phrase list\n",
    "#         #return the pair of phrase by useing dic\n",
    "        curpair = unique_phrase_list[cur_pair_phrase_dic[np.max(score_list_current_iter)]] \n",
    "#         #count how many phrase in cur_touched_phrase \n",
    "        count_now = 0\n",
    "        for loc in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[loc] in curpair:\n",
    "                count_now+=1\n",
    "        if count_now>=2 and curpair in unique_phrase_list:\n",
    "#             print('hahahahahahhaa six six six')\n",
    "            unique_phrase_list.remove(curpair)\n",
    "        count +=1\n",
    "        #remove phrase list\n",
    "        #unique_phrase_list.remove(curpair)\n",
    "        #remove sentence\n",
    "        sentence_list.remove(high_sen)\n",
    "        \n",
    "        #add cur touched list to total touched list\n",
    "        for inx in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[inx] not in touched_phrase_list:\n",
    "                touched_phrase_list.append(cur_touched_phrase[inx])\n",
    "        print('now total touched length', len(touched_phrase_list))\n",
    "    return answer_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengh of touched phrase 1\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 0\n",
      "now total touched length 1\n",
      "lengh of touched phrase 1\n",
      "now total touched length 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 2\n",
      "lengh of touched phrase 0\n",
      "now total touched length 2\n",
      "lengh of touched phrase 1\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 4\n",
      "now total touched length 7\n"
     ]
    }
   ],
   "source": [
    "answer = BM25_score(list(list_sentence),list(unique_phrase_list),p_list.copy(),200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Considering that hGIIA-sPLA2 enzyme is known to hydrolyze glyceroacylphospholipids present in lipoproteins and cell membranes, maslinic acid may bind and inhibit hGIIA-sPLA2 enzymatic activity, thereby reduces the release of fatty acids and lysophospholipids which stimulates monocyte migration and differentiation',\n",
       " ' Two bacterial species frequently involved in biofilm-associated infections, Staphylococcus aureus and Aggregatibacter actinomycetemcomitans, were used as model organisms; their initial adhesion and biofilm formation on titanium and on antibacterial copper were analyzed using the following methods: LIVE/DEAD fluorescence staining and confocal laser-scanning microscopy, ultrasonic or a newly developed enzymatic detachment followed by standard plate counting (CFU method), a resazurin-based assay, the BacTiter-Gloâ\\x84¢ assay and crystal violet staining',\n",
       " ' The intermediate vinyl radical cyclizes intramolecularly and yields the product after rearomatization',\n",
       " ' Molecular docking revealed that maslinic acid binds to calcium binding and interfacial phospholipid binding site, suggesting that it inhibit access of catalytic calcium ion for enzymatic reaction and block binding of the enzyme to membrane phospholipid',\n",
       " ' A variety of aromatic carboxylic acids including 2-nitrobenzoic acids, pentafluorobenzoic acid and several heteroaromatic carboxylic acids undergo efficient thiolation to furnish the aryl sulfides in moderate to excellent yields',\n",
       " ' This high activity was attributed to its high internalization in MCF-7 cells, as shown by flow cytometry, and to the subsequent release of the ligand by the intracellular cleavage of the enzyme-labile spacer, as observed in cathepsin B enzymatic assays',\n",
       " ' When analyzed using gas chromatography/electron ionization-mass spectrometry (GC/EI-MS), unsaturated FAME with DMDS added to the double bonds yields high intensity MS spectra of characteristic ions',\n",
       " ' Although often very effective in hampering microbial adhesion, natural epitopes often show limited resistance to enzymatic degradation',\n",
       " ' Our method detected more than 70 oxidised lipids biosynthesised from two non-enzymatic and three enzymatic pathways in urine samples',\n",
       " ' The positive effect of isonucleotides at A15 and T8 along with inherent enzymatic resistance could be a tangible solution for the practical applications of 10-23 DNAzyme',\n",
       " ' Spasm can be promptly and effectively treated if recognized early, and treatment with nitrate therapy is often sufficient to abolish spasm',\n",
       " '1-(2-Bromophenyl)-1H-pyrrole and 1-(2,6-dibromophenyl)-1H-pyrrole react in the presence of catalytic amounts of rhodamine 6G () and N,N-diisopropylethylamine (DIPEA) under blue light irradiation with aromatic alkynes and subsequently cyclize intramolecularly to form pyrrolo[1,2-a]quinoline and ullazines',\n",
       " 'Clinical record of five patients (including one familial case) with osteogenesis imperfecta type V were retrospectively analyzed',\n",
       " ' Total baseline plasma homocysteine was measured using an enzymatic cycling assay',\n",
       " ' Samples were analyzed with different experimental methods, such as scanning electron microscopy (SEM), Reflection spectro-photometry and antibacterial test',\n",
       " ' The effects of intermolecular contacts on the structure were investigated; such contacts cause only highly localized distortions, as judged from the degree of molecular asymmetry that they induce',\n",
       " ' Our study reveals a mechanism that ensures site-specific NCP ubiquitination and fine-tuning of opposing enzymatic activities',\n",
       " '1 A resolution and its implications in the mechanism of water oxidatio Oxygen-evolving complex of photosystem II (PSII) is a tetra-manganese calcium penta-oxygenic cluster (Mn4CaO5) catalyzing light-induced water oxidation through several intermediate states (S-states) by a mechanism that is not fully understood',\n",
       " ' Continuous monitoring and management of the groundwater system is needed to minimize groundwater pollution in these areas, and this information should be shared among adjacent countries with similar geographic and cultural settings',\n",
       " 'The primary and three-dimensional structures of a nine-haem cytochrome c from Desulfovibrio desulfuricans ATCC 27774 reveal a new member of the Hmc family Haem-containing proteins are directly involved in electron transfer as well as in enzymatic functions']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

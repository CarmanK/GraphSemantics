{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the json file from kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_layer_1 = pd.read_json('../output_data/layer_1_output_10.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the pair of unique phrase in layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phrase_list = np.unique(data_df_layer_1['phrase'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATCC W3', 'ATCC photosystem II', 'Ca ATCC', 'Ca Cu', 'Ca W3',\n",
       "       'Ca aromatic ring', 'Ca copper', 'Ca photosystem II', 'Ca redox',\n",
       "       'Cu ATCC', 'Cu W3', 'Cu aromatic ring', 'Cu copper',\n",
       "       'Cu photosystem II', 'Cu redox', 'Sr ATCC', 'Sr Ca', 'Sr Cu',\n",
       "       'Sr W3', 'Sr aromatic ring', 'Sr copper', 'Sr photosystem II',\n",
       "       'Sr redox', 'Sr sulfite', 'W3 photosystem II',\n",
       "       'aromatic ring ATCC', 'aromatic ring W3', 'aromatic ring copper',\n",
       "       'aromatic ring photosystem II', 'aromatic ring redox',\n",
       "       'copper ATCC', 'copper W3', 'copper photosystem II',\n",
       "       'copper redox', 'redox ATCC', 'redox W3', 'redox photosystem II',\n",
       "       'sulfite ATCC', 'sulfite Ca', 'sulfite Cu', 'sulfite W3',\n",
       "       'sulfite aromatic ring', 'sulfite copper',\n",
       "       'sulfite photosystem II', 'sulfite redox'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the unique phrase in layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = list(pd.read_json('./top_k_output/layer_1.json',typ='series').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of list(unique phrase) for current pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop throught every pair of phrase\n",
    "list_of_phrase_list = []\n",
    "for i in range(len(unique_phrase_list)):\n",
    "    tmplist =[]\n",
    "    for j in range(len(p_list)):\n",
    "        if p_list[j] in unique_phrase_list[i]:\n",
    "            tmplist.append(p_list[j])\n",
    "    list_of_phrase_list.append(tmplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention: Every sentence in the articles from the pool is a candidate sentence for the final summary.\n",
    "# step: compute a BM25 score for every candidate sentence\n",
    "\n",
    "# to compute BM25\n",
    "# 1. find all sentence in current layer(done)\n",
    "# 2. index all sentence(done)\n",
    "# 3. compute score for all current sentence\n",
    "# 4. question here-> should we use the sentence with highest score \n",
    "# to cover the phrase? or to cover pair of phrase?\n",
    "# If so, after phrase been recoverd, tag the sentence been used,\n",
    "# recompute the BM25 in unused sentence pool\n",
    "# and iterate all sentece until all phrase been coverd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the article pool now\n",
    "article_list = data_df_layer_1['article'].values\n",
    "#for each article, find all sentence\n",
    "article_list[0]\n",
    "sentence_dic = {}\n",
    "list_sentence = []\n",
    "s_count = 0 #sentence index\n",
    "for i in range(len(article_list)):\n",
    "    #for every sentence, if not in sentence_list, push sentence in list\n",
    "    tmp_sentence_list = article_list[i].split(\".\")\n",
    "    for j in range(len(tmp_sentence_list)):\n",
    "        if tmp_sentence_list[j] not in article_list:\n",
    "            sentence_dic[s_count] = tmp_sentence_list[j]\n",
    "            list_sentence.append(tmp_sentence_list[j])\n",
    "            s_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentence = np.unique(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25_score(sentence_list,unique_phrase_list,p_list):\n",
    "    #at each iteration\n",
    "    #find the sentence that could lead to the highest bm25\n",
    "        #1.for every pair of phrase, find the max score of that sentence, save that score and the respective sentence,\n",
    "        #2.pick the highest score, also recover that sentence\n",
    "        #3.find how many phrase this sentece been touched, tag those phrase, pop those phrase out of phrase list\n",
    "        #4.if pair of phrase that lead to highest score contains all some at least two of phrase that been poped out,\n",
    "        #5.pop out that phrase pair in pair list\n",
    "        #6.finsihed current iteration\n",
    "        #7.check whether the lenght of phrass list becomes 0 or num of iteration hit max\n",
    "        #8.if either happens, exit the problem, return the sentence list, and the touched phrase list\n",
    "        \n",
    "    \n",
    "    answer_sentence_list = []\n",
    "    touched_phrase_list = []\n",
    "    count = 0\n",
    "    while len(p_list) > 0 and len(touched_phrase_list) < len(p_list):\n",
    "        #step1\n",
    "        #create a data structure to save score for current query(as pair of phrase)\n",
    "        #in the future, implement the max-heap ds here O(nlogn) push, O(1) peek\n",
    "        score_list_current_iter = []\n",
    "        sentence_idx_list = []\n",
    "        cur_pair_phrase_dic = {}\n",
    "        for i in range(len(unique_phrase_list)):\n",
    "            #compute bm25 score use current phrase pair as query\n",
    "            bm25 = BM25Okapi(sentence_list) #create class of bm25\n",
    "            doc_scores = bm25.get_scores(unique_phrase_list[i])\n",
    "            sentence_loc = np.argmax(doc_scores)  #the index num of max-score sentence in the sen_list\n",
    "            sentence_score = np.max(doc_scores)   #the max score over all score of sentence for current query\n",
    "            score_list_current_iter.append(sentence_score)\n",
    "            sentence_idx_list.append(sentence_loc)\n",
    "            if sentence_score not in cur_pair_phrase_dic:\n",
    "                cur_pair_phrase_dic[sentence_score] = i\n",
    "        #step2\n",
    "        highest_score_index = np.argmax(score_list_current_iter)\n",
    "        high_sen = sentence_list[sentence_idx_list[highest_score_index]] \n",
    "        answer_sentence_list.append(high_sen)\n",
    "        #step three\n",
    "        cur_touched_phrase = []  #record how many phrase been touched by this sentence\n",
    "#         print('current lengh of p_list is', len(p_list))\n",
    "        list_deleted = []\n",
    "        for pos in range(len(p_list)):\n",
    "#             print('current pos is', pos)\n",
    "#             print('what is that ', p_list[pos])\n",
    "            if p_list[pos] in high_sen:\n",
    "                if p_list[pos] not in cur_touched_phrase:\n",
    "                    cur_touched_phrase.append(p_list[pos])\n",
    "#                 p_list.remove(p_list[pos])\n",
    "                #remove phrase list\n",
    "        #<wait>\n",
    "#         for i in range(len(cur_touched_phrase)):\n",
    "#             if cur_touched_phrase[i] in p_list:\n",
    "#                 p_list.remove(cur_touched_phrase[i])\n",
    "        #<wait>\n",
    "#         print('current sentence is', sentence_list[highest_score_index])\n",
    "#         print('len of unique pair  list', len(unique_phrase_list))\n",
    "        print('lengh of touched phrase', len(cur_touched_phrase))\n",
    "#         print('current count is', count)\n",
    "#         print('lengh of sentence list', len(sentence_list))\n",
    "\n",
    "#         #if the current pair of phrase that lead to this sentence which has max score contains two phrase in cur_touched_phrase\n",
    "#         #pop this pair of phrase out of pair of phrase list\n",
    "#         #return the pair of phrase by useing dic\n",
    "        curpair = unique_phrase_list[cur_pair_phrase_dic[np.max(score_list_current_iter)]] \n",
    "#         #count how many phrase in cur_touched_phrase \n",
    "        count_now = 0\n",
    "        for loc in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[loc] in curpair:\n",
    "                count_now+=1\n",
    "        if count_now>=2 and curpair in unique_phrase_list:\n",
    "#             print('hahahahahahhaa six six six')\n",
    "            unique_phrase_list.remove(curpair)\n",
    "        count +=1\n",
    "        #remove phrase list\n",
    "        #unique_phrase_list.remove(curpair)\n",
    "        #remove sentence\n",
    "        sentence_list.remove(high_sen)\n",
    "        \n",
    "        #add cur touched list to total touched list\n",
    "        for inx in range(len(cur_touched_phrase)):\n",
    "            if cur_touched_phrase[inx] not in touched_phrase_list:\n",
    "                touched_phrase_list.append(cur_touched_phrase[inx])\n",
    "        print('now total touched length', len(touched_phrase_list))\n",
    "        #create a pair phrase function based on the cur_touched_phrase_process\n",
    "        tmp_phrase_pair = []\n",
    "        for p in range(len(cur_touched_phrase)):\n",
    "            for q in range(p,len(cur_touched_phrase)):\n",
    "                if cur_touched_phrase[p] != cur_touched_phrase[q]:\n",
    "                    tmp_phrase_pair.append([cur_touched_phrase[p],cur_touched_phrase[q]])\n",
    "        #iter thorught unique_phrase_list if pair is exist in touched list, dequeue them\n",
    "        \n",
    "        deletelist = []\n",
    "#         print('tmo coutched list is', len(tmp_phrase_pair))\n",
    "#         print('tmp phrase pari look like ', tmp_phrase_pair)\n",
    "        for p2 in range(len(tmp_phrase_pair)):\n",
    "            for q2 in range(len(unique_phrase_list)):\n",
    "                if tmp_phrase_pair[p2][0] in unique_phrase_list[q2] and tmp_phrase_pair[p2][1] in unique_phrase_list[q2]:\n",
    "                    if unique_phrase_list[q2] not in deletelist:\n",
    "                        deletelist.append(unique_phrase_list[q2])\n",
    "        \n",
    "#         print('look of deletelist, ', deletelist)\n",
    "#         print('len of delete list', len(deletelist))\n",
    "        for p3 in range(len(deletelist)):\n",
    "            if deletelist[p3] in unique_phrase_list:\n",
    "                unique_phrase_list.remove(deletelist[p3])\n",
    "#         print('len of unique list is', len(unique_phrase_list))\n",
    "#         print('num of iteration now is', count)\n",
    "    return answer_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengh of touched phrase 2\n",
      "now total touched length 2\n",
      "lengh of touched phrase 1\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 0\n",
      "now total touched length 3\n",
      "lengh of touched phrase 1\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 1\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 0\n",
      "now total touched length 4\n",
      "lengh of touched phrase 3\n",
      "now total touched length 5\n",
      "lengh of touched phrase 2\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 1\n",
      "now total touched length 6\n",
      "lengh of touched phrase 0\n",
      "now total touched length 6\n",
      "lengh of touched phrase 2\n",
      "now total touched length 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "lengh of touched phrase 0\n",
      "now total touched length 7\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 2\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 1\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 0\n",
      "now total touched length 8\n",
      "lengh of touched phrase 3\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 2\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 2\n",
      "now total touched length 9\n",
      "lengh of touched phrase 2\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 0\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 9\n",
      "lengh of touched phrase 1\n",
      "now total touched length 10\n"
     ]
    }
   ],
   "source": [
    "answer = BM25_score(list(list_sentence),list(unique_phrase_list),p_list.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

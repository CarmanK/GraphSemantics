{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from rank_bm25 import BM25Okapi\n",
    "import json\n",
    "from termcolor import colored\n",
    "import re\n",
    "import itertools\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output_data/tmp/article_pool.json', 'r') as input_file:\n",
    "    phrase_list = json.load(input_file)\n",
    "\n",
    "data_df_layer_1 = pd.DataFrame(phrase_list[0])\n",
    "layer_num = len(phrase_list)\n",
    "unique_phrase_list = np.unique(data_df_layer_1['phrase'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = list(pd.read_json('./output_data/tmp/selected_phrases.json',typ='series')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_phrase_list = []\n",
    "for i in range(len(unique_phrase_list)):\n",
    "    tmplist =[]\n",
    "    for j in range(len(p_list)):\n",
    "        if p_list[j] in unique_phrase_list[i]:\n",
    "            tmplist.append(p_list[j])\n",
    "    list_of_phrase_list.append(tmplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentece_list(unique_phrase_list):\n",
    "    list_of_phrase_list = []\n",
    "    for i in range(len(unique_phrase_list)):\n",
    "        tmplist =[]\n",
    "        for j in range(len(p_list)):\n",
    "            if p_list[j] in unique_phrase_list[i]:\n",
    "                tmplist.append(p_list[j])\n",
    "        list_of_phrase_list.append(tmplist)\n",
    "    return list_of_phrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#create the article pool now\n",
    "article_list = data_df_layer_1['article'].values\n",
    "#for each article, find all sentence\n",
    "sentence_dic = {}\n",
    "list_sentence = []\n",
    "s_count = 0 #sentence index\n",
    "for i in range(len(article_list)):\n",
    "    #for every sentence, if not in sentence_list, push sentence in list\n",
    "    tmp_sentence_list = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', article_list[i])\n",
    "    for j in range(len(tmp_sentence_list)):\n",
    "#         if tmp_sentence_list[j] not in article_list:\n",
    "        sentence_dic[s_count] = tmp_sentence_list[j]\n",
    "        list_sentence.append(tmp_sentence_list[j])        \n",
    "        s_count +=1\n",
    "list_sentence = np.unique(list_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sulfite',\n",
       " 'aromatic ring',\n",
       " 'copper',\n",
       " 'redox',\n",
       " 'ATCC',\n",
       " 'Desulfovibrio desulfuricans',\n",
       " 'catalytic activity',\n",
       " 'kinetics',\n",
       " 'partially reduced',\n",
       " 'photosystem II']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sulfite', 'aromatic ring'), ('sulfite', 'copper'), ('sulfite', 'redox'), ('sulfite', 'ATCC'), ('sulfite', 'Desulfovibrio desulfuricans'), ('sulfite', 'catalytic activity'), ('sulfite', 'kinetics'), ('sulfite', 'partially reduced'), ('sulfite', 'photosystem II'), ('aromatic ring', 'copper'), ('aromatic ring', 'redox'), ('aromatic ring', 'ATCC'), ('aromatic ring', 'Desulfovibrio desulfuricans'), ('aromatic ring', 'catalytic activity'), ('aromatic ring', 'kinetics'), ('aromatic ring', 'partially reduced'), ('aromatic ring', 'photosystem II'), ('copper', 'redox'), ('copper', 'ATCC'), ('copper', 'Desulfovibrio desulfuricans'), ('copper', 'catalytic activity'), ('copper', 'kinetics'), ('copper', 'partially reduced'), ('copper', 'photosystem II'), ('redox', 'ATCC'), ('redox', 'Desulfovibrio desulfuricans'), ('redox', 'catalytic activity'), ('redox', 'kinetics'), ('redox', 'partially reduced'), ('redox', 'photosystem II'), ('ATCC', 'Desulfovibrio desulfuricans'), ('ATCC', 'catalytic activity'), ('ATCC', 'kinetics'), ('ATCC', 'partially reduced'), ('ATCC', 'photosystem II'), ('Desulfovibrio desulfuricans', 'catalytic activity'), ('Desulfovibrio desulfuricans', 'kinetics'), ('Desulfovibrio desulfuricans', 'partially reduced'), ('Desulfovibrio desulfuricans', 'photosystem II'), ('catalytic activity', 'kinetics'), ('catalytic activity', 'partially reduced'), ('catalytic activity', 'photosystem II'), ('kinetics', 'partially reduced'), ('kinetics', 'photosystem II'), ('partially reduced', 'photosystem II')]\n"
     ]
    }
   ],
   "source": [
    "print(list(itertools.combinations(p_list,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(itertools.combinations(p_list,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sulfite', 'aromatic ring', 'copper']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATCC Desulfovibrio desulfuricans', 'ATCC catalytic activity',\n",
       "       'ATCC kinetics', 'ATCC partially reduced', 'ATCC photosystem II',\n",
       "       'Desulfovibrio desulfuricans catalytic activity',\n",
       "       'Desulfovibrio desulfuricans kinetics',\n",
       "       'Desulfovibrio desulfuricans partially reduced',\n",
       "       'Desulfovibrio desulfuricans photosystem II', 'aromatic ring ATCC',\n",
       "       'aromatic ring Desulfovibrio desulfuricans',\n",
       "       'aromatic ring catalytic activity', 'aromatic ring copper',\n",
       "       'aromatic ring kinetics', 'aromatic ring partially reduced',\n",
       "       'aromatic ring photosystem II', 'aromatic ring redox',\n",
       "       'catalytic activity kinetics',\n",
       "       'catalytic activity partially reduced',\n",
       "       'catalytic activity photosystem II', 'copper ATCC',\n",
       "       'copper Desulfovibrio desulfuricans', 'copper catalytic activity',\n",
       "       'copper kinetics', 'copper partially reduced',\n",
       "       'copper photosystem II', 'copper redox',\n",
       "       'kinetics partially reduced', 'kinetics photosystem II',\n",
       "       'partially reduced photosystem II', 'redox ATCC',\n",
       "       'redox Desulfovibrio desulfuricans', 'redox catalytic activity',\n",
       "       'redox kinetics', 'redox partially reduced',\n",
       "       'redox photosystem II', 'sulfite ATCC',\n",
       "       'sulfite Desulfovibrio desulfuricans', 'sulfite aromatic ring',\n",
       "       'sulfite catalytic activity', 'sulfite copper', 'sulfite kinetics',\n",
       "       'sulfite partially reduced', 'sulfite photosystem II',\n",
       "       'sulfite redox'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination: 10  choose  10  current lengh of ans is 0\n",
      "combination: 10  choose  9  current lengh of ans is 0\n",
      "combination: 10  choose  8  current lengh of ans is 0\n",
      "combination: 10  choose  7  current lengh of ans is 0\n",
      "combination: 10  choose  6  current lengh of ans is 0\n",
      "combination: 10  choose  5  current lengh of ans is 0\n",
      "combination: 10  choose  4  current lengh of ans is 0\n",
      "combination: 10  choose  3  current lengh of ans is 1\n",
      "combination: 10  choose  2  current lengh of ans is 19\n",
      "combination: 10  choose  1  current lengh of ans is 355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ven_diagram(list_sentence,unique_phrase_list,p_list):\n",
    "    #generate the list of list\n",
    "    list_of_list_com = []\n",
    "    counter = len(p_list)\n",
    "    while counter > 0:\n",
    "        list_of_list_com.append(list(itertools.combinations(p_list,counter)))\n",
    "        counter-=1\n",
    "        \n",
    "    #venn cover\n",
    "    len_p_list = len(p_list)#len of p_list\n",
    "    #find the sentence that matches current cover\n",
    "    ans = []\n",
    "    for i in range(len(list_of_list_com)):\n",
    "        for j in range(len(list_of_list_com[i])):\n",
    "            #find the phrase list that not in com_list\n",
    "            cur_list = list(list_of_list_com[i][j])\n",
    "            not_in_list = []\n",
    "            for pos in range(len(p_list)):\n",
    "                if p_list[pos] not in cur_list:\n",
    "                    not_in_list.append(p_list[pos])\n",
    "            \n",
    "            #find the sentence that cover all phrase in list_of_list_com[i][j] and not covered in not_in_list\n",
    "            for p in  range(len(list_sentence)):\n",
    "                flag_good = True\n",
    "                flag_good_filter = True\n",
    "                for q in range(len(cur_list)):\n",
    "                    if cur_list[q] not in list_sentence[p]:\n",
    "                        flag_good = False\n",
    "                        break\n",
    "                for g in range(len(not_in_list)):\n",
    "                    if not_in_list[g] in list_sentence[p]:\n",
    "                        flag_good_filter = False\n",
    "                        break\n",
    "                #pass all exam\n",
    "                #push current setence to result\n",
    "                if flag_good==True and flag_good_filter==True and list_sentence[p] not in ans:\n",
    "                    ans.append(list_sentence[p])\n",
    "                    \n",
    "        print('combination:',len_p_list,' choose ',len_p_list - i,' current lengh of ans is', len(ans))\n",
    "                    \n",
    "    return ans\n",
    "\n",
    "a = ven_diagram(list_sentence.copy(),unique_phrase_list,p_list)\n",
    "len(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def set_cover(sentence_list,unique_phrase_list,p_list):\n",
    "    #at each iteration\n",
    "        #find the sentence that cover most number of unvisted phrase\n",
    "        #mark those phrase as visited (pop)\n",
    "        #mark the sentence as visited (pop)\n",
    "    answer_sentence_list = []\n",
    "    touch_count_dic = []\n",
    "    count = 0\n",
    "    while len(p_list) > 0:\n",
    "        #create a data structure to save how many unvisited phrase the current sentence touched\n",
    "        touch_count_dic = {} #key as num of phrase touched, value is a list of index of sentence\n",
    "        global_max_count = 0\n",
    "        for i in range(len(sentence_list)):\n",
    "            #compute num of touched\n",
    "            tmpcount = 0\n",
    "            for j in range(len(p_list)):\n",
    "                if p_list[j] in sentence_list[i]:\n",
    "                    tmpcount+=1\n",
    "            if tmpcount > global_max_count:\n",
    "                global_max_count = tmpcount\n",
    "            # save current result in dic\n",
    "            if tmpcount in touch_count_dic:\n",
    "                #return the list\n",
    "                curlist = touch_count_dic.get(tmpcount)\n",
    "                curlist.append(i)\n",
    "            else:\n",
    "                tmplist = []\n",
    "                tmplist.append(i)\n",
    "                touch_count_dic[tmpcount] = tmplist\n",
    "        #use the global max count to return lit of index of sentence that lead to the max current count\n",
    "        \n",
    "        list_of_max_index_sentence = touch_count_dic[global_max_count]\n",
    "        #pick the first one\n",
    "        selected_max_sentence_index = list_of_max_index_sentence[0]\n",
    "        selected_max_sentence = sentence_list[selected_max_sentence_index]\n",
    "        #set cover\n",
    "        visited_list = []\n",
    "#         print('what is sentence now', selected_max_sentence)\n",
    "        \n",
    "        for loc in range(len(p_list)):\n",
    "            if p_list[loc] in selected_max_sentence and p_list[loc] not in visited_list:\n",
    "                visited_list.append(p_list[loc])\n",
    "        #delete all visited list\n",
    "        print('!!!! visted list is', len(visited_list))\n",
    "#         print('what is sentence now', selected_max_sentence)\n",
    "        for pos2 in range(len(visited_list)):\n",
    "            p_list.remove(visited_list[pos2])\n",
    "        answer_sentence_list.append(selected_max_sentence)\n",
    "        #remove the current sentencn\n",
    "        sentence_list.pop(selected_max_sentence_index)\n",
    "#         print('length of sentence list is', len(sentence_list))\n",
    "#         print('len of remainng list', p_list)\n",
    "    return answer_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def annotating_function(answer,p_list): #only mark the first occurance of a phrase exist in sentence\n",
    "    #iter through every answer\n",
    "    for i in range(len(answer)):\n",
    "        for j in range(len(p_list)):\n",
    "            if p_list[j] in answer[i]:\n",
    "                #find the starting index\n",
    "                start = answer[i].find(p_list[j])\n",
    "                end = start + len(p_list[j])\n",
    "                answer[i] = answer[i][0:start] + colored(p_list[j],'red') + answer[i][end:]\n",
    "    for i in range(len(answer)):\n",
    "        print('index :', i, '', answer[i] +'\\n')\n",
    "\n",
    "\n",
    "#%%\n",
    "def main_func():\n",
    "    with open('./output_data/tmp/article_pool.json', 'r') as input_file:\n",
    "        phrase_list = json.load(input_file)\n",
    "    layer_num = len(phrase_list)  #how many layer\n",
    "    full_output = []\n",
    "    for i in range(layer_num):\n",
    "        data_df_layer_1 = pd.DataFrame(phrase_list[i])\n",
    "        unique_phrase_list = np.unique(data_df_layer_1['phrase'].values)\n",
    "        p_list = list(pd.read_json('./output_data/tmp/selected_phrases.json',typ='series')[i])\n",
    "#         list_of_phrase_list =  create_sentece_list(unique_phrase_list)\n",
    "        list_sentence = create_sentence_pool(data_df_layer_1)\n",
    "        #run\n",
    "        answer = ven_diagram(list(list_sentence),list(unique_phrase_list),p_list.copy())\n",
    "        full_output.append(answer)          \n",
    "        print('current layer is: ',i )\n",
    "        annotating_function(answer.copy(),p_list)\n",
    "\n",
    "    with open('./output_data/summaries.json', 'w') as outfile:\n",
    "            json.dump(full_output, outfile, indent = 4)\n",
    "\n",
    "\n",
    "#%%\n",
    "# Runs the entire program\n",
    "main_func()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
